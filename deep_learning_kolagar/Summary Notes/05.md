

# خلاصه نکات کلیدی: توابع هزینه (Loss Functions)

### ۱. تفاوت محاسبه خطا در انواع مسائل
نوع تابع هزینه‌ای که انتخاب می‌کنیم، مستقیماً به نوع مسئله (رگرسیون یا دسته‌بندی) بستگی دارد:

| ویژگی | رگرسیون (Regression) | دسته‌بندی (Classification) |
| :--- | :--- | :--- |
| **هدف** | پیش‌بینی یک مقدار عددی (مثلاً قیمت) | تشخیص کلاس ورودی (مثلاً سگ یا گربه) |
| **لایه خروجی** | معمولاً **۱ نورون** | تعداد نورون = **تعداد کلاس‌ها** |
| **خروجی مطلوب** | یک عدد پیوسته | بردار احتمالات (مجموع ۱ می‌شود) |
| **روش محاسبه خطا** | MSE (نرم L2) یا MAE (نرم L1) | **Cross-Entropy (آنتروپی متقاطع)** |



---

### ۲. نکات مهم در مسائل کلاسیفیکیشن (Classification)

* **کدگذاری خروجی واقعی (True Label):** از روش **One-Hot Encoding** استفاده می‌شود.
    * کلاس صحیح = ۱
    * سایر کلاس‌ها = ۰
    * *مثال:* برای ۳ کلاس (اسب، سگ، گربه)، اگر تصویر سگ باشد: `[0, 1, 0]`

* **تفسیر خروجی مدل (Prediction):** خروجی شبکه به صورت **احتمال** بیان می‌شود (مثلاً ۴۰٪ یا ۰.۴).

---

### ۳. تحلیل تابع کراس آنتروپی (Cross-Entropy)

فرمول کلیدی برای محاسبه خطا در دسته‌بندی:

$$Loss = - \sum (y_{true} \times \ln(y_{predict}))$$

**نکات کنکوری فرمول:**
1.  **اثر کلاس‌های غلط:** چون مقدار واقعی ($y_{true}$) برای کلاس‌های غلط **صفر** است، ضرب در لگاریتم شده و حذف می‌شوند. **تنها کلاس صحیح در محاسبه خطا نقش دارد.**
2.  **رابطه لگاریتم و خطا:**
    * اگر شبکه مطمئن باشد ($y_{predict} \approx 1$) $\leftarrow$ $\ln(1) = 0$ $\leftarrow$ **خطا صفر است.**
    * اگر شبکه شک داشته باشد ($y_{predict} < 1$) $\leftarrow$ مقدار لگاریتم منفی بزرگ می‌شود $\leftarrow$ **خطا زیاد می‌شود.**




### ۴. مثال سریع (جمع‌بندی ویدیو)
فرض کنید پاسخ صحیح "کلاس دوم" است: `[0, 1, 0]`

* **حالت بد (خطای بالا):** پیش‌بینی `[0.4, 0.4, 0.2]`
    * شبکه فقط ۴۰٪ مطمئن است.
    * محاسبه: $-1 \times \ln(0.4) \approx 0.96$ (خطای زیاد).
* **حالت عالی (خطای صفر):** پیش‌بینی `[0, 1, 0]`
    * شبکه ۱۰۰٪ مطمئن است.
    * محاسبه: $-1 \times \ln(1) = 0$ (بدون خطا).

---
