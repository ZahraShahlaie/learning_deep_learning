
---

### بخش اول: مفاهیم پایه و معماری شبکه

**سوال ۱: تفاوت اصلی معماری لایه خروجی (Output Layer) در مسائل رگرسیون و کلاسیفیکیشن چیست؟**
**پاسخ:**
در مسائل **رگرسیون**، چون هدف پیش‌بینی یک مقدار عددی پیوسته است، لایه خروجی معمولاً دارای **یک نورون** است. اما در مسائل **کلاسیفیکیشن** (دسته‌بندی)، تعداد نورون‌های لایه خروجی برابر با **تعداد کلاس‌های مسئله** است (مثلاً اگر ۳ کلاس اسب، سگ و گربه داشته باشیم، ۳ نورون خروجی داریم).

**سوال ۲: برای محاسبه خطا در مسائل رگرسیون از چه توابعی استفاده می‌شود؟**
**پاسخ:**
معمولاً از توابع زیر استفاده می‌شود:
1.  **MSE (Mean Squared Error):** یا خطای میانگین مربعات که به آن نرم L2 هم گفته می‌شود.
2.  **MAE (Mean Absolute Error):** یا خطای میانگین قدر مطلق که به آن نرم L1 گفته می‌شود.

---

### بخش دوم: توابع هزینه و محاسبات (تمرکز بر کلاسیفیکیشن)

**سوال ۳: در مسائل کلاسیفیکیشن چند کلاسه، داده‌های برچسب واقعی (True Labels) باید با چه فرمتی به تابع هزینه داده شوند؟**
**پاسخ:**
داده‌های واقعی باید با روش **One-Hot Encoding** کدگذاری شوند. در این روش، یک بردار به طول تعداد کلاس‌ها داریم که اندیس کلاس صحیح برابر با **۱** و سایر اندیس‌ها برابر با **۰** هستند. (مثال: `[0, 1, 0]` برای کلاس دوم).

**سوال ۴: تابع هزینه Cross-Entropy (کراس آنتروپی) چگونه محاسبه می‌شود و فرمول آن چیست؟**
**پاسخ:**
این تابع میزان تفاوت بین توزیع احتمال پیش‌بینی شده و توزیع واقعی را اندازه می‌گیرد. فرمول آن برای یک نمونه به صورت زیر است:
$$Loss = - \sum (y_{true} \times \ln(y_{predict}))$$
که در آن $y_{true}$ مقدار واقعی و $y_{predict}$ احتمال پیش‌بینی شده توسط مدل است.

**سوال ۵: در محاسبه دستی Cross-Entropy، چرا عملاً فقط احتمالِ "کلاس صحیح" مهم است؟**
**پاسخ:**
چون در بردار One-Hot، مقدار $y_{true}$ برای تمام کلاس‌های نادرست برابر با **صفر** است. وقتی صفر در لگاریتم پیش‌بینی ضرب می‌شود، آن عبارت حذف می‌گردد. بنابراین، فقط جمله‌ای باقی می‌ماند که $y_{true}$ آن **یک** است (کلاس صحیح).

---

### بخش سوم: سوالات مفهومی و تحلیلی

**سوال ۶: چرا وقتی مدل با اطمینان ۱۰۰٪ کلاس درست را پیش‌بینی می‌کند، مقدار Loss صفر می‌شود؟ (اثبات ریاضی)**
**پاسخ:**
اگر مدل کاملاً مطمئن باشد، یعنی $y_{predict}$ برای کلاس صحیح برابر با **۱** است. از آنجا که لگاریتم طبیعی یک برابر با صفر است ($\ln(1) = 0$)، حاصل‌ضرب $1 \times 0$ در فرمول کراس آنتروپی باعث می‌شود کل مقدار خطا **صفر** شود.

**سوال ۷: اگر خروجی مدل برای کلاس صحیح عدد کمی (مثلاً ۰.۴) باشد، چه اتفاقی برای مقدار Loss می‌افتد و مفهوم آن چیست؟**
**پاسخ:**
وقتی احتمال پیش‌بینی شده کم باشد (مثلاً ۰.۴)، یعنی مدل اعتماد کمی به پاسخ خود دارد. از نظر ریاضی، $\ln(0.4)$ یک عدد منفی می‌شود و وقتی در منفیِ فرمول ضرب شود، یک عدد مثبت بزرگ (مثلاً ۰.۹۶) تولید می‌کند. این یعنی **خطای زیاد**. بنابراین تابع هزینه، مدل را به خاطر عدم اطمینان یا پیش‌بینی اشتباه به شدت جریمه می‌کند.

**سوال ۸: خروجی لایه آخر در شبکه عصبی برای کلاسیفیکیشن چه ویژگی‌ای دارد؟**
**پاسخ:**
خروجی‌ها بیانگر **احتمال** تعلق ورودی به هر کلاس هستند. این مقادیر معمولاً بین ۰ و ۱ قرار دارند و استفاده از اکتیویشن فانکشن مناسب باعث می‌شود این خروجی‌ها قابل تفسیر به عنوان احتمال باشند.


---

### بخش چهارم: جزئیات فنی و مقایسه‌ای

**سوال ۹: تابع‌های هزینه MAE (نرم L1) و MSE (نرم L2) در مسائل رگرسیون چه تفاوتی در نحوه جریمه کردن خطاها دارند؟**
**پاسخ:**
هر دو برای اندازه‌گیری فاصله بین پیش‌بینی و مقدار واقعی استفاده می‌شوند:
* **MAE (L1 Norm):** خطای **قدر مطلق** است و خطاها را به صورت خطی جریمه می‌کند. (نسبت به نقاط پرت (Outliers) مقاوم‌تر است.)
* **MSE (L2 Norm):** خطای **مربعات** است و خطاها را به صورت درجه دوم جریمه می‌کند. (خطاهای بزرگ را به شدت بیشتر جریمه می‌کند و به نقاط پرت بسیار حساس است.)

**سوال ۱۰: در یک مسئله کلاسیفیکیشن، قبل از محاسبه کراس آنتروپی، خروجی لایه آخر باید چه خاصیتی داشته باشد و این خاصیت چگونه ایجاد می‌شود؟**
**پاسخ:**
خروجی لایه آخر باید به صورت **احتمالاتی** باشد؛ یعنی مقادیر هر کلاس بین ۰ و ۱ بوده و مجموع آن‌ها برابر با ۱ شود. این خاصیت توسط یک **تابع فعال‌ساز (Activation Function)** مناسب (مانند Softmax) در لایه خروجی ایجاد می‌شود.

**سوال ۱۱: در فرمول کراس آنتروپی، مفهوم **سیگما ($\Sigma$)** که برای جمع‌بندی استفاده می‌شود، چیست؟**
**پاسخ:**
سیگما ($\Sigma$) نشان‌دهنده **جمع‌بندی** حاصل‌ضرب $y_{true} \times \ln(y_{predict})$ **به ازای تمام کلاس‌ها (اندیس‌ها)** است.
$$CrossEntropy = - \sum_{i} (y_{true, i} \times \ln(y_{predict, i}))$$
به دلیل استفاده از One-Hot Encoding، عملاً فقط یک ترم از این جمع باقی می‌ماند (جمله‌ای که $y_{true}$ آن ۱ است)، اما سیگما نشان‌دهنده این است که باید به طور بالقوه تأثیر تمام کلاس‌ها را در نظر گرفت.

**سوال ۱۲: بر اساس مثال عددی ارائه شده در ویدیو (پیش‌بینی ۰.۴ برای کلاس صحیح)، آیا مقدار خطا منطقی بود؟ چرا؟**
**پاسخ:**
**خیر، منطقی نبود.**
* مقدار خطای محاسبه شده تقریباً **۰.۹۶** شد.
* این مقدار بالا (نزدیک به ۱) نشان‌دهنده **وضعیت خراب** مدل و **عدم اطمینان کافی** آن بود. اگر مدل به‌خوبی آموزش دیده بود، برای یک نمونه صحیح باید مقداری نزدیک به صفر حاصل می‌شد.

---
